Model,Technique,IFR,Preservation
GPT2-XL,AlphaEdit,0.736,0.9034188034188033
GPT2-XL,MEMIT,0.727,0.8803418803418802
GPT2-XL,MEMIT-prune,0.25,0.782051282
GPT2-XL,MEMIT-rect,0.754,0.8504273504273504
GPT2-XL,ROME,0.279,0.7521367521367521
Llama-3-8B,AlphaEdit,0.678,0.900089606
Llama-3-8B,MEMIT,0.8,0.9112903225806451
Llama-3-8B,MEMIT-prune,0.309,0.6468894009216589
Llama-3-8B,MEMIT-rect,0.894,0.8803763440860214
Llama-3-8B,ROME,0.217,0.5705325140809011
Qwen2.5-7B,AlphaEdit,0.391,0.9173856209150327
Qwen2.5-7B,MEMIT,0.394,0.8652521008403361
Qwen2.5-7B,MEMIT-prune,0.411,0.5872082166199813
Qwen2.5-7B,MEMIT-rect,0.525,0.8227124183006536
Qwen2.5-7B,ROME,0.261,0.5372549019607843
